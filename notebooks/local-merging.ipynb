{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION']='.95'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 14:59:03.067388: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-11 14:59:03.080694: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-11 14:59:03.080711: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-11 14:59:03.575708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-10-11 14:59:04.365362: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ekansh/anaconda3/envs/vision-models/lib/python3.9/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from configs import finetune\n",
    "from data import input_pipeline\n",
    "import models\n",
    "import utils\n",
    "from utils import restore_checkpoint\n",
    "from permutations import *\n",
    "from constants import *\n",
    "from pruning import apply_mask\n",
    "\n",
    "from configs.eval_merge import get_config\n",
    "import merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import update_batch_stats\n",
    "import functools\n",
    "from flax.training import common_utils\n",
    "from trainer import compute_metrics\n",
    "\n",
    "def get_metrics(metrics):\n",
    "    return common_utils.stack_forest(metrics)\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnums=(0,))\n",
    "def eval_step(apply_fn, params, batch):\n",
    "    logits = apply_fn(params, batch['image'], deterministic=True)\n",
    "    metrics = compute_metrics(logits, batch['label'])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_loss_and_accuracy(apply_fn, params, dataset, nbatches=None):\n",
    "    eval_iter = input_pipeline.prefetch(dataset, 10, None)\n",
    "    eval_metrics = []\n",
    "    ix = 0\n",
    "    for eval_batch in eval_iter:\n",
    "        metrics = eval_step(apply_fn, params, eval_batch)\n",
    "        eval_metrics.append(metrics)\n",
    "        ix+=1\n",
    "        if nbatches is not None:\n",
    "            if ix >= nbatches:\n",
    "                break\n",
    "\n",
    "    eval_metrics = get_metrics(eval_metrics)\n",
    "    summary = {\n",
    "            f'eval_{k}': v\n",
    "            for k, v in jax.tree_util.tree_map(\n",
    "            lambda x: x.mean(), eval_metrics\n",
    "            ).items()\n",
    "    }\n",
    "\n",
    "    return summary['eval_loss'], summary['eval_accuracy']\n",
    "\n",
    "\n",
    "\n",
    "norm_acc = lambda acc, expert_acc: acc / expert_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ViTB16'\n",
    "ntasks = 8\n",
    "tasks = TASKS_A[:ntasks//2] + TASKS_B[:ntasks//2]\n",
    "datasets = \".\".join(tasks)\n",
    "config = get_config(f\"{model_name},{datasets},average-merging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'VGG16':\n",
    "  config.width_multiplier = 2\n",
    "  for dataset in DATASETS:\n",
    "    config[dataset].pp.crop = crop = 96\n",
    "    config[dataset].model_dir = VGG16X2_A[dataset]\n",
    "  config.local_init = VGG16X2_NONLOCAL_TASK_A_INIT\n",
    "elif model_name == 'ViTB16':\n",
    "  for dataset in DATASETS:\n",
    "    config[dataset].pp.crop = crop = 224\n",
    "    config[dataset].model_dir = VITB16[dataset]\n",
    "  config.local_init = VITB16_INIT\n",
    "elif model_name == 'ViTmaeB16':\n",
    "  for dataset in DATASETS:\n",
    "    config[dataset].pp.crop = crop = 224\n",
    "    config[dataset].model_dir = VITMAEB16[dataset]\n",
    "  config.local_init = VITMAEB16_INIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/colorectal_histology/2.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar10/3.0.2\n",
      "INFO:absl:For 'cifar10/3.0.2': fields info.[splits, supervised_keys] differ on disk and in the code. Keeping the one from code.\n",
      "INFO:absl:No config specified, defaulting to config: eurosat/rgb\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/eurosat/rgb/2.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/oxford_iiit_pet/3.2.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/resisc45/3.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar100/3.0.2\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cassava/0.1.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/svhn_cropped/3.0.0\n",
      "INFO:absl:For 'svhn_cropped/3.0.0': fields info.[description, citation, module_name] differ on disk and in the code. Keeping the one from code.\n",
      "INFO:absl:Reading dataset from tfds \"colorectal_histology\"\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/colorectal_histology/2.0.0\n",
      "INFO:absl:Reusing dataset colorectal_histology (/mnt/MintStorage/data/tensorflow_datasets/colorectal_histology/2.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset colorectal_histology for split train[:90%], from /mnt/MintStorage/data/tensorflow_datasets/colorectal_histology/2.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/colorectal_histology/2.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/colorectal_histology/2.0.0\n",
      "INFO:absl:Reusing dataset colorectal_histology (/mnt/MintStorage/data/tensorflow_datasets/colorectal_histology/2.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset colorectal_histology for split train[90%:], from /mnt/MintStorage/data/tensorflow_datasets/colorectal_histology/2.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/colorectal_histology/2.0.0\n",
      "INFO:absl:Reading dataset from tfds \"cifar10\"\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar10/3.0.2\n",
      "INFO:absl:For 'cifar10/3.0.2': fields info.[splits, supervised_keys] differ on disk and in the code. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset cifar10 (/mnt/MintStorage/data/tensorflow_datasets/cifar10/3.0.2)\n",
      "INFO:absl:Constructing tf.data.Dataset cifar10 for split train, from /mnt/MintStorage/data/tensorflow_datasets/cifar10/3.0.2\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar10/3.0.2\n",
      "INFO:absl:For 'cifar10/3.0.2': fields info.[splits, supervised_keys] differ on disk and in the code. Keeping the one from code.\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar10/3.0.2\n",
      "INFO:absl:For 'cifar10/3.0.2': fields info.[splits, supervised_keys] differ on disk and in the code. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset cifar10 (/mnt/MintStorage/data/tensorflow_datasets/cifar10/3.0.2)\n",
      "INFO:absl:Constructing tf.data.Dataset cifar10 for split test, from /mnt/MintStorage/data/tensorflow_datasets/cifar10/3.0.2\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar10/3.0.2\n",
      "INFO:absl:For 'cifar10/3.0.2': fields info.[splits, supervised_keys] differ on disk and in the code. Keeping the one from code.\n",
      "INFO:absl:Reading dataset from tfds \"eurosat\"\n",
      "INFO:absl:No config specified, defaulting to config: eurosat/rgb\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/eurosat/rgb/2.0.0\n",
      "INFO:absl:Reusing dataset eurosat (/mnt/MintStorage/data/tensorflow_datasets/eurosat/rgb/2.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset eurosat for split train[:90%], from /mnt/MintStorage/data/tensorflow_datasets/eurosat/rgb/2.0.0\n",
      "INFO:absl:No config specified, defaulting to config: eurosat/rgb\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/eurosat/rgb/2.0.0\n",
      "INFO:absl:No config specified, defaulting to config: eurosat/rgb\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/eurosat/rgb/2.0.0\n",
      "INFO:absl:Reusing dataset eurosat (/mnt/MintStorage/data/tensorflow_datasets/eurosat/rgb/2.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset eurosat for split train[90%:], from /mnt/MintStorage/data/tensorflow_datasets/eurosat/rgb/2.0.0\n",
      "INFO:absl:No config specified, defaulting to config: eurosat/rgb\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/eurosat/rgb/2.0.0\n",
      "INFO:absl:Reading dataset from tfds \"oxford_iiit_pet\"\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/oxford_iiit_pet/3.2.0\n",
      "INFO:absl:Reusing dataset oxford_iiit_pet (/mnt/MintStorage/data/tensorflow_datasets/oxford_iiit_pet/3.2.0)\n",
      "INFO:absl:Constructing tf.data.Dataset oxford_iiit_pet for split train, from /mnt/MintStorage/data/tensorflow_datasets/oxford_iiit_pet/3.2.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/oxford_iiit_pet/3.2.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/oxford_iiit_pet/3.2.0\n",
      "INFO:absl:Reusing dataset oxford_iiit_pet (/mnt/MintStorage/data/tensorflow_datasets/oxford_iiit_pet/3.2.0)\n",
      "INFO:absl:Constructing tf.data.Dataset oxford_iiit_pet for split test[:90%], from /mnt/MintStorage/data/tensorflow_datasets/oxford_iiit_pet/3.2.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/oxford_iiit_pet/3.2.0\n",
      "INFO:absl:Reading dataset from tfds \"resisc45\"\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/resisc45/3.0.0\n",
      "INFO:absl:Reusing dataset resisc45 (/mnt/MintStorage/data/tensorflow_datasets/resisc45/3.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset resisc45 for split train[10%:90%], from /mnt/MintStorage/data/tensorflow_datasets/resisc45/3.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/resisc45/3.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/resisc45/3.0.0\n",
      "INFO:absl:Reusing dataset resisc45 (/mnt/MintStorage/data/tensorflow_datasets/resisc45/3.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset resisc45 for split train[90%:], from /mnt/MintStorage/data/tensorflow_datasets/resisc45/3.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/resisc45/3.0.0\n",
      "INFO:absl:Reading dataset from tfds \"cifar100\"\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar100/3.0.2\n",
      "INFO:absl:Reusing dataset cifar100 (/mnt/MintStorage/data/tensorflow_datasets/cifar100/3.0.2)\n",
      "INFO:absl:Constructing tf.data.Dataset cifar100 for split train, from /mnt/MintStorage/data/tensorflow_datasets/cifar100/3.0.2\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar100/3.0.2\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar100/3.0.2\n",
      "INFO:absl:Reusing dataset cifar100 (/mnt/MintStorage/data/tensorflow_datasets/cifar100/3.0.2)\n",
      "INFO:absl:Constructing tf.data.Dataset cifar100 for split test, from /mnt/MintStorage/data/tensorflow_datasets/cifar100/3.0.2\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cifar100/3.0.2\n",
      "INFO:absl:Reading dataset from tfds \"cassava\"\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cassava/0.1.0\n",
      "INFO:absl:Reusing dataset cassava (/mnt/MintStorage/data/tensorflow_datasets/cassava/0.1.0)\n",
      "INFO:absl:Constructing tf.data.Dataset cassava for split train, from /mnt/MintStorage/data/tensorflow_datasets/cassava/0.1.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cassava/0.1.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cassava/0.1.0\n",
      "INFO:absl:Reusing dataset cassava (/mnt/MintStorage/data/tensorflow_datasets/cassava/0.1.0)\n",
      "INFO:absl:Constructing tf.data.Dataset cassava for split test, from /mnt/MintStorage/data/tensorflow_datasets/cassava/0.1.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/cassava/0.1.0\n",
      "INFO:absl:Reading dataset from tfds \"svhn_cropped\"\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/svhn_cropped/3.0.0\n",
      "INFO:absl:For 'svhn_cropped/3.0.0': fields info.[description, citation, module_name] differ on disk and in the code. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset svhn_cropped (/mnt/MintStorage/data/tensorflow_datasets/svhn_cropped/3.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset svhn_cropped for split train, from /mnt/MintStorage/data/tensorflow_datasets/svhn_cropped/3.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/svhn_cropped/3.0.0\n",
      "INFO:absl:For 'svhn_cropped/3.0.0': fields info.[description, citation, module_name] differ on disk and in the code. Keeping the one from code.\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/svhn_cropped/3.0.0\n",
      "INFO:absl:For 'svhn_cropped/3.0.0': fields info.[description, citation, module_name] differ on disk and in the code. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset svhn_cropped (/mnt/MintStorage/data/tensorflow_datasets/svhn_cropped/3.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset svhn_cropped for split test, from /mnt/MintStorage/data/tensorflow_datasets/svhn_cropped/3.0.0\n",
      "INFO:absl:Load dataset info from /mnt/MintStorage/data/tensorflow_datasets/svhn_cropped/3.0.0\n",
      "INFO:absl:For 'svhn_cropped/3.0.0': fields info.[description, citation, module_name] differ on disk and in the code. Keeping the one from code.\n"
     ]
    }
   ],
   "source": [
    "datasets = config.datasets\n",
    "dataset_info_ls = [input_pipeline.get_dataset_info(dataset, config[dataset].pp['train']) for dataset in config.datasets]\n",
    "num_classes = [dataset_info['num_classes'] for dataset_info in dataset_info_ls] \n",
    "num_train_examples = [dataset_info['num_examples'] for dataset_info in dataset_info_ls]\n",
    "\n",
    "ds_train_ls, ds_test_ls = input_pipeline.get_datasets_for_mtl(config, datasets, batch_size=128)\n",
    "\n",
    "model_ls = []\n",
    "model_tracker_ls = []\n",
    "model_repaired_ls = []\n",
    "param_dirs = []\n",
    "\n",
    "for i, nclass in enumerate(num_classes): \n",
    "  model_ls += [models.create_model(model_cls=getattr(models, config.model), num_classes=nclass, half_precision=False, projection_dim=512, width_multiplier=config.width_multiplier)]\n",
    "  model_tracker_ls += [models.create_model(model_cls=getattr(models, config.model), num_classes=nclass, half_precision=False, projection_dim=512, width_multiplier=config.width_multiplier, tracker=True)]\n",
    "  model_repaired_ls += [models.create_model(model_cls=getattr(models, config.model), num_classes=nclass, half_precision=False, projection_dim=512, width_multiplier=config.width_multiplier, repaired=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading expert models for colorectal_histology from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/colorectal_histology/sgd/steps_10000_500/cosine_1e-3/seed_0.\n",
      "INFO:absl:Restoring orbax checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/colorectal_histology/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000\n",
      "INFO:absl:Restoring item from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/colorectal_histology/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:absl:Finished restoring checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/colorectal_histology/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:root:Loading expert models for cifar10 from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cifar10/sgd/steps_10000_500/cosine_1e-3/seed_0.\n",
      "INFO:absl:Restoring orbax checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cifar10/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000\n",
      "INFO:absl:Restoring item from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cifar10/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:absl:Finished restoring checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cifar10/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:root:Loading expert models for eurosat from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/eurosat/sgd/steps_10000_500/cosine_1e-3/seed_0.\n",
      "INFO:absl:Restoring orbax checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/eurosat/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000\n",
      "INFO:absl:Restoring item from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/eurosat/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:absl:Finished restoring checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/eurosat/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:root:Loading expert models for oxford_iiit_pet from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/oxford_iiit_pet/sgd/steps_10000_500/cosine_1e-3/seed_0.\n",
      "INFO:absl:Restoring orbax checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/oxford_iiit_pet/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000\n",
      "INFO:absl:Restoring item from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/oxford_iiit_pet/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:absl:Finished restoring checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/oxford_iiit_pet/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:root:Loading expert models for resisc45 from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/resisc45/sgd/steps_10000_500/cosine_1e-3/seed_0.\n",
      "INFO:absl:Restoring orbax checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/resisc45/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000\n",
      "INFO:absl:Restoring item from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/resisc45/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:absl:Finished restoring checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/resisc45/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:root:Loading expert models for cifar100 from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cifar100/sgd/steps_10000_500/cosine_1e-3/seed_0.\n",
      "INFO:absl:Restoring orbax checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cifar100/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000\n",
      "INFO:absl:Restoring item from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cifar100/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:absl:Finished restoring checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cifar100/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:root:Loading expert models for cassava from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cassava/sgd/steps_10000_500/cosine_1e-3/seed_0.\n",
      "INFO:absl:Restoring orbax checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cassava/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000\n",
      "INFO:absl:Restoring item from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cassava/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:absl:Finished restoring checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cassava/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:root:Loading expert models for svhn_cropped from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/svhn_cropped/sgd/steps_10000_500/cosine_1e-3/seed_0.\n",
      "INFO:absl:Restoring orbax checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/svhn_cropped/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000\n",
      "INFO:absl:Restoring item from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/svhn_cropped/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n",
      "INFO:absl:Finished restoring checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/svhn_cropped/sgd/steps_10000_500/cosine_1e-3/seed_0/checkpoint_10000.\n"
     ]
    }
   ],
   "source": [
    "## Load expert parameters\n",
    "expert_params_ls = []\n",
    "\n",
    "for ix, dataset in enumerate(datasets):\n",
    "  logging.info(f\"Loading expert models for {dataset} from {config[dataset].model_dir}.\")\n",
    "  raw_state = restore_checkpoint(config[dataset].model_dir)\n",
    "  expert_params = {'params': raw_state['params']}\n",
    "  expert_params_ls += [expert_params]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Restoring orbax checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cassava/sgd/steps_10000_500/cosine_1e-3/seed_0/init/checkpoint_0\n",
      "INFO:absl:Restoring item from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cassava/sgd/steps_10000_500/cosine_1e-3/seed_0/init/checkpoint_0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Finished restoring checkpoint from /home/ekansh/repos/share/vision-models/experiments/ViTB16/hugging_face/cassava/sgd/steps_10000_500/cosine_1e-3/seed_0/init/checkpoint_0.\n"
     ]
    }
   ],
   "source": [
    "## Load init parameters\n",
    "raw_state_init = restore_checkpoint(config.local_init)\n",
    "init_params = {'params': raw_state_init['params']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params['params'].pop('classifier')\n",
    "classifiers_ls = [expert_params['params'].pop('classifier') for expert_params in expert_params_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 14:59:20.276972: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colorectal_histology expert accuracy = 0.9713541865348816\n",
      "colorectal_histology expert loss = 0.11431100964546204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 14:59:39.292576: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10 expert accuracy = 0.9886819124221802\n",
      "cifar10 expert loss = 0.03868929296731949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 14:59:45.405243: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eurosat expert accuracy = 0.9866071343421936\n",
      "eurosat expert loss = 0.03653038293123245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 14:59:52.686324: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oxford_iiit_pet expert accuracy = 0.9359375238418579\n",
      "oxford_iiit_pet expert loss = 0.23676452040672302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 14:59:59.561591: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resisc45 expert accuracy = 0.9518229365348816\n",
      "resisc45 expert loss = 0.15293549001216888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:00:18.668679: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar100 expert accuracy = 0.9278846383094788\n",
      "cifar100 expert loss = 0.24418126046657562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:00:23.428058: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cassava expert accuracy = 0.87890625\n",
      "cassava expert loss = 0.5140537619590759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:01:10.803897: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svhn_cropped expert accuracy = 0.951662540435791\n",
      "svhn_cropped expert loss = 0.17149339616298676\n"
     ]
    }
   ],
   "source": [
    "## Expert accuracies:\n",
    "expert_loss = {}\n",
    "expert_accs = {}\n",
    "\n",
    "for ix, dataset in enumerate(datasets):\n",
    "  expert_params_ls[ix]['params']['classifier'] = classifiers_ls[ix]\n",
    "  loss, accuracy = compute_loss_and_accuracy(model_ls[ix].apply, expert_params_ls[ix], ds_test_ls[ix])\n",
    "  expert_loss[dataset] = loss\n",
    "  expert_accs[dataset] = accuracy\n",
    "  expert_params_ls[ix]['params'].pop('classifier')\n",
    "  print(f\"{dataset} expert accuracy = {accuracy}\")\n",
    "  print(f\"{dataset} expert loss = {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA+TALL\n"
     ]
    }
   ],
   "source": [
    "tall_mask = False\n",
    "task_vectors = [utils.tree_subtract(params['params'], init_params['params']) for params  in expert_params_ls]  \n",
    "\n",
    "## Task-arithmetic model-merging: \n",
    "# print(\"TA\")\n",
    "# lam = 0.4\n",
    "# t_MTL = merging.compute_task_arithmetic_vector(task_vectors, lam)\n",
    "# merged_params  = {'params': utils.tree_add(t_MTL, init_params['params'])}\n",
    "\n",
    "## TIES model-merging: \n",
    "# print(\"TIES\")\n",
    "# lam=0.8\n",
    "# t_MTL = merging.compute_ties_vector(task_vectors, lam)\n",
    "# merged_params  = {'params': utils.tree_add(t_MTL, init_params['params'])}\n",
    "\n",
    "## TA+TALL model-merging: \n",
    "print(\"TA+TALL\")\n",
    "lam=0.5\n",
    "t_MTL = merging.compute_ties_vector(task_vectors, lam)\n",
    "t_masks_ls = [merging.compute_tall_mask(task_vector, t_MTL) for task_vector in task_vectors]\n",
    "tall_mask = True\n",
    "\n",
    "## TIES+TALL model-merging: \n",
    "# print(\"TIES\")\n",
    "# lam=0.8\n",
    "# t_MTL = merging.compute_ties_vector(task_vectors, lam)\n",
    "# t_masks_ls = [merging.compute_tall_mask(task_vector, t_MTL) for task_vector in task_vectors]\n",
    "# tall_mask = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:01:25.520331: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colorectal_histology\n",
      "merged accuracy = 0.8854166865348816\n",
      "normalized accuracy = 0.9115281701087952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:01:40.270881: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10\n",
      "merged accuracy = 0.9820713400840759\n",
      "normalized accuracy = 0.993313729763031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:01:44.836987: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eurosat\n",
      "merged accuracy = 0.9583333134651184\n",
      "normalized accuracy = 0.9713423848152161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:01:50.264191: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oxford_iiit_pet\n",
      "merged accuracy = 0.9290624856948853\n",
      "normalized accuracy = 0.9926543831825256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:01:55.492136: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resisc45\n",
      "merged accuracy = 0.8541666865348816\n",
      "normalized accuracy = 0.8974007964134216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:02:11.940054: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar100\n",
      "merged accuracy = 0.8890224099159241\n",
      "normalized accuracy = 0.9581173658370972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:02:15.136629: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cassava\n",
      "merged accuracy = 0.81640625\n",
      "normalized accuracy = 0.9288889169692993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:02:57.801059: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svhn_cropped\n",
      "merged accuracy = 0.5591133236885071\n",
      "normalized accuracy = 0.587512195110321\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "merged_accuracies = {}\n",
    "merged_normalized_accuracies = {}\n",
    "for ix, dataset in enumerate(datasets):\n",
    "  if tall_mask:\n",
    "    merged_params = {'params' : utils.tree_add(init_params['params'], apply_mask(t_MTL, t_masks_ls[ix]))}\n",
    "  merged_params['params']['classifier'] = classifiers_ls[ix]\n",
    "  loss, accuracy = compute_loss_and_accuracy(model_ls[ix].apply, merged_params, ds_test_ls[ix])\n",
    "  merged_accuracies[dataset] = accuracy\n",
    "  merged_normalized_accuracies[dataset] = norm_acc(accuracy, expert_accs[dataset])\n",
    "  merged_params['params'].pop('classifier')\n",
    "  print(f'{dataset}')\n",
    "  print(f\"merged accuracy = {accuracy}\")\n",
    "  print(f\"normalized accuracy = {norm_acc(accuracy, expert_accs[dataset])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:03:04.891045: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 770744320 bytes after encountering the first element of size 77074432 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:09:51.965663: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 246706 bytes after encountering the first element of size 246706 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:09:58.185862: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 329372 bytes after encountering the first element of size 329372 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "2024-10-11 15:10:04.229536: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 329372 bytes after encountering the first element of size 329372 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:10:10.459498: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 329372 bytes after encountering the first element of size 329372 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-10-11 15:10:16.690001: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 334159 bytes after encountering the first element of size 334159 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:10:22.912751: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 246706 bytes after encountering the first element of size 246706 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "2024-10-11 15:10:28.956164: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 329372 bytes after encountering the first element of size 329372 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "## Compute output statistics for expert parameters\n",
    "expert_batch_stats_ls = []\n",
    "rng = random.PRNGKey(0)\n",
    "for ix, dataset in enumerate(datasets):\n",
    "  expert_params_ls[ix]['params']['classifier'] = classifiers_ls[ix]\n",
    "  params_tracker = models.load_from_source(model_tracker_ls[ix].initialization(rng, (1, crop, crop, 3)), {'params': expert_params_ls[ix]['params']})\n",
    "  params_tracker = update_batch_stats(model_tracker_ls[ix].apply, params_tracker, ds_train_ls[ix], nbatches=500)\n",
    "  expert_batch_stats_ls += [params_tracker['batch_stats']]\n",
    "  expert_params_ls[ix]['params'].pop('classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TACT accuracy for colorectal_histology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:20:16.345234: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9375\n",
      "normalized accuracy = 0.9651474356651306\n",
      "Computing TACT accuracy for cifar10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:22:28.260773: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9850761294364929\n",
      "normalized accuracy = 0.9963529109954834\n",
      "Computing TACT accuracy for eurosat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:24:29.941816: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9713541865348816\n",
      "normalized accuracy = 0.9845399856567383\n",
      "Computing TACT accuracy for oxford_iiit_pet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:25:20.690608: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 329372 bytes after encountering the first element of size 329372 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:25:27.066705: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 248348 bytes after encountering the first element of size 248348 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:25:33.256844: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 334159 bytes after encountering the first element of size 334159 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "2024-10-11 15:25:39.644334: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 329372 bytes after encountering the first element of size 329372 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "2024-10-11 15:25:46.021824: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 246706 bytes after encountering the first element of size 246706 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:25:52.398396: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 334159 bytes after encountering the first element of size 334159 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:25:58.600064: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 329372 bytes after encountering the first element of size 329372 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "2024-10-11 15:26:04.997342: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 329372 bytes after encountering the first element of size 329372 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "2024-10-11 15:26:11.395784: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 329372 bytes after encountering the first element of size 329372 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:26:17.793221: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 246706 bytes after encountering the first element of size 246706 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-10-11 15:26:24.005226: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 248348 bytes after encountering the first element of size 248348 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "2024-10-11 15:26:35.127623: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9318749904632568\n",
      "normalized accuracy = 0.9956594109535217\n",
      "Computing TACT accuracy for resisc45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:28:41.094999: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9091796875\n",
      "normalized accuracy = 0.955198347568512\n",
      "Computing TACT accuracy for cifar100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:30:55.071808: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9099559187889099\n",
      "normalized accuracy = 0.9806778430938721\n",
      "Computing TACT accuracy for cassava\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:33:02.920560: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8381696343421936\n",
      "normalized accuracy = 0.9536507725715637\n",
      "Computing TACT accuracy for svhn_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:35:43.824877: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8748460412025452\n",
      "normalized accuracy = 0.9192817807197571\n"
     ]
    }
   ],
   "source": [
    "tact_accuracies = {}\n",
    "tact_normalized_accuracies = {}\n",
    "\n",
    "for ix, dataset in enumerate(datasets):\n",
    "  print(f\"Computing TACT accuracy for {dataset}\")\n",
    "  if tall_mask:\n",
    "    merged_params = {'params' : utils.tree_add(init_params['params'], apply_mask(t_MTL, t_masks_ls[ix]))}\n",
    "  merged_params_tact = models.load_from_source(model_repaired_ls[ix].initialization(rng, (1, crop, crop, 3)), merged_params)\n",
    "  merged_params_tact = models.set_batch_norm_params_from_batch_stats(merged_params_tact, expert_batch_stats_ls[ix])\n",
    "  merged_params_tact['params']['classifier'] = classifiers_ls[ix]\n",
    "  merged_params_tact = update_batch_stats(model_repaired_ls[ix].apply, merged_params_tact,  ds_train_ls[ix], nbatches=500)\n",
    "  loss, accuracy = compute_loss_and_accuracy(model_repaired_ls[ix].apply, merged_params_tact, ds_test_ls[ix])\n",
    "  tact_accuracies[dataset] = accuracy\n",
    "  tact_normalized_accuracies[dataset] = norm_acc(accuracy, expert_accs[dataset])\n",
    "  print(f\"accuracy = {tact_accuracies[dataset]}\")\n",
    "  print(f\"normalized accuracy = {tact_normalized_accuracies[dataset]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: colorectal_histology\n",
      "\tExpert accuracy = 0.9713541865348816; Merged model accuracy = 0.8854166865348816; Merged + TACT accuracy = 0.9375\n",
      "\n",
      "Dataset: cifar10\n",
      "\tExpert accuracy = 0.9886819124221802; Merged model accuracy = 0.9820713400840759; Merged + TACT accuracy = 0.9850761294364929\n",
      "\n",
      "Dataset: eurosat\n",
      "\tExpert accuracy = 0.9866071343421936; Merged model accuracy = 0.9583333134651184; Merged + TACT accuracy = 0.9713541865348816\n",
      "\n",
      "Dataset: oxford_iiit_pet\n",
      "\tExpert accuracy = 0.9359375238418579; Merged model accuracy = 0.9290624856948853; Merged + TACT accuracy = 0.9318749904632568\n",
      "\n",
      "Dataset: resisc45\n",
      "\tExpert accuracy = 0.9518229365348816; Merged model accuracy = 0.8541666865348816; Merged + TACT accuracy = 0.9091796875\n",
      "\n",
      "Dataset: cifar100\n",
      "\tExpert accuracy = 0.9278846383094788; Merged model accuracy = 0.8890224099159241; Merged + TACT accuracy = 0.9099559187889099\n",
      "\n",
      "Dataset: cassava\n",
      "\tExpert accuracy = 0.87890625; Merged model accuracy = 0.81640625; Merged + TACT accuracy = 0.8381696343421936\n",
      "\n",
      "Dataset: svhn_cropped\n",
      "\tExpert accuracy = 0.951662540435791; Merged model accuracy = 0.5591133236885071; Merged + TACT accuracy = 0.8748460412025452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ix, dataset in enumerate(datasets):\n",
    "  print(f\"Dataset: {dataset}\")\n",
    "  print(f\"\\tExpert accuracy = {expert_accs[dataset]}; Merged model accuracy = {merged_accuracies[dataset]}; Merged + TACT accuracy = {tact_accuracies[dataset]}\")\n",
    "  print(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
